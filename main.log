[1744856857] Log start
[1744856857] Cmd: /home/matt/projects/llama.cpp/main -m /home/matt/projects/llama.cpp/models/llava/v1.6-mistral-7b-q4_k_m.gguf -p "Do you have history from our previous chat?" --ctx_size 2048 --temp 0.7 --n_predict 1024 --no-mmap
[1744856857] main: build = 2409 (306d34be)
[1744856857] main: built with cc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0 for x86_64-linux-gnu
[1744856857] main: seed  = 1744856857
[1744856857] main: llama backend init
[1744856857] main: load the model and apply lora adapter, if any
[1744856857] llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /home/matt/projects/llama.cpp/models/llava/v1.6-mistral-7b-q4_k_m.gguf (version GGUF V3 (latest))
[1744856857] llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
[1744856857] llama_model_loader: - kv   0:                       general.architecture str              = llama
[1744856857] llama_model_loader: - kv   1:                               general.name str              = models
[1744856857] llama_model_loader: - kv   2:                       llama.context_length u32              = 32768
[1744856857] llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096
[1744856857] llama_model_loader: - kv   4:                          llama.block_count u32              = 32
[1744856857] llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336
[1744856857] llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128
[1744856857] llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32
[1744856857] llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8
[1744856857] llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010
[1744856857] llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000
[1744856857] llama_model_loader: - kv  11:                          general.file_type u32              = 15
[1744856857] llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama
[1744856857] llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = ["<unk>", "<s>", "</s>", "<0x00>", "<...
[1744856857] llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...
[1744856857] llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...
[1744856857] llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1
[1744856857] llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2
[1744856857] llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0
[1744856857] llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0
[1744856857] llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true
[1744856857] llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false
[1744856857] llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...
[1744856857] llama_model_loader: - kv  23:               general.quantization_version u32              = 2
[1744856857] llama_model_loader: - type  f32:   65 tensors
[1744856857] llama_model_loader: - type q4_K:  193 tensors
[1744856857] llama_model_loader: - type q6_K:   33 tensors
[1744856857] llm_load_vocab: special tokens definition check successful ( 259/32000 ).
[1744856857] llm_load_print_meta: format           = GGUF V3 (latest)
[1744856857] llm_load_print_meta: arch             = llama
[1744856857] llm_load_print_meta: vocab type       = SPM
[1744856857] llm_load_print_meta: n_vocab          = 32000
[1744856857] llm_load_print_meta: n_merges         = 0
[1744856857] llm_load_print_meta: n_ctx_train      = 32768
[1744856857] llm_load_print_meta: n_embd           = 4096
[1744856857] llm_load_print_meta: n_head           = 32
[1744856857] llm_load_print_meta: n_head_kv        = 8
[1744856857] llm_load_print_meta: n_layer          = 32
[1744856857] llm_load_print_meta: n_rot            = 128
[1744856857] llm_load_print_meta: n_embd_head_k    = 128
[1744856857] llm_load_print_meta: n_embd_head_v    = 128
[1744856857] llm_load_print_meta: n_gqa            = 4
[1744856857] llm_load_print_meta: n_embd_k_gqa     = 1024
[1744856857] llm_load_print_meta: n_embd_v_gqa     = 1024
[1744856857] llm_load_print_meta: f_norm_eps       = 0.0e+00
[1744856857] llm_load_print_meta: f_norm_rms_eps   = 1.0e-05
[1744856857] llm_load_print_meta: f_clamp_kqv      = 0.0e+00
[1744856857] llm_load_print_meta: f_max_alibi_bias = 0.0e+00
[1744856857] llm_load_print_meta: n_ff             = 14336
[1744856857] llm_load_print_meta: n_expert         = 0
[1744856857] llm_load_print_meta: n_expert_used    = 0
[1744856857] llm_load_print_meta: causal attm      = 1
[1744856857] llm_load_print_meta: pooling type     = 0
[1744856857] llm_load_print_meta: rope type        = 0
[1744856857] llm_load_print_meta: rope scaling     = linear
[1744856857] llm_load_print_meta: freq_base_train  = 1000000.0
[1744856857] llm_load_print_meta: freq_scale_train = 1
[1744856857] llm_load_print_meta: n_yarn_orig_ctx  = 32768
[1744856857] llm_load_print_meta: rope_finetuned   = unknown
[1744856857] llm_load_print_meta: ssm_d_conv       = 0
[1744856857] llm_load_print_meta: ssm_d_inner      = 0
[1744856857] llm_load_print_meta: ssm_d_state      = 0
[1744856857] llm_load_print_meta: ssm_dt_rank      = 0
[1744856857] llm_load_print_meta: model type       = 7B
[1744856857] llm_load_print_meta: model ftype      = Q4_K - Medium
[1744856857] llm_load_print_meta: model params     = 7.24 B
[1744856857] llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) 
[1744856857] llm_load_print_meta: general.name     = models
[1744856857] llm_load_print_meta: BOS token        = 1 '<s>'
[1744856857] llm_load_print_meta: EOS token        = 2 '</s>'
[1744856857] llm_load_print_meta: UNK token        = 0 '<unk>'
[1744856857] llm_load_print_meta: PAD token        = 0 '<unk>'
[1744856857] llm_load_print_meta: LF token         = 13 '<0x0A>'
[1744856857] llm_load_tensors: ggml ctx size =    0.11 MiB
[1744856857] llm_load_tensors:        CPU buffer size =  4165.37 MiB
[1744856857] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856858] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] .[1744856859] 
[1744856859] llama_new_context_with_model: n_ctx      = 2048
[1744856859] llama_new_context_with_model: freq_base  = 1000000.0
[1744856859] llama_new_context_with_model: freq_scale = 1
[1744856859] llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB
[1744856859] llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB
[1744856859] llama_new_context_with_model:        CPU input buffer size   =    13.02 MiB
[1744856859] llama_new_context_with_model:        CPU compute buffer size =   160.00 MiB
[1744856859] llama_new_context_with_model: graph splits (measure): 1
[1744856859] warming up the model with an empty run
[1744856859] n_ctx: 2048
[1744856859] 
[1744856859] system_info: n_threads = 6 / 12 | AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 1 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | 
[1744856859] add_bos: 1
[1744856859] tokenize the prompt
[1744856859] prompt: "Do you have history from our previous chat?"
[1744856859] tokens: [ '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804 ]
[1744856859] recalculate the cached logits (check): embd_inp.empty() false, n_matching_session_tokens 0, embd_inp.size() 10, session_tokens.size() 0, embd_inp.size() 10
[1744856859] inp_pfx: [ '':1, ' ':28705, '':13, '':13, '###':27332, ' Inst':3133, 'ruction':3112, ':':28747, '':13, '':13 ]
[1744856859] inp_sfx: [ ' ':28705, '':13, '':13, '###':27332, ' Response':12107, ':':28747, '':13, '':13 ]
[1744856859] cml_pfx: [ '':1, ' ':28705, '':13, '<':28789, '|':28766, 'im':321, '_':28730, 'start':2521, '|':28766, '>':28767, 'user':1838, '':13 ]
[1744856859] cml_sfx: [ ' <':523, '|':28766, 'im':321, '_':28730, 'end':416, '|':28766, '>':28767, '':13, '<':28789, '|':28766, 'im':321, '_':28730, 'start':2521, '|':28766, '>':28767, 'ass':489, 'istant':11143, '':13 ]
[1744856859] sampling: 
	repeat_last_n = 64, repeat_penalty = 1.100, frequency_penalty = 0.000, presence_penalty = 0.000
	top_k = 40, tfs_z = 1.000, top_p = 0.950, min_p = 0.050, typical_p = 1.000, temp = 0.700
	mirostat = 0, mirostat_lr = 0.100, mirostat_ent = 5.000
[1744856859] sampling order: 
CFG -> Penalties -> top_k -> tfs_z -> typical_p -> top_p -> min_p -> temperature 
[1744856859] generate: n_ctx = 2048, n_batch = 512, n_predict = 1024, n_keep = 1
[1744856859] 

[1744856859] embd_inp.size(): 10, n_consumed: 0
[1744856859] eval: [ '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804 ]
[1744856860] n_past = 10
[1744856860] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13 ]
[1744856860] n_remain: 1023
[1744856860] eval: [ '':13 ]
[1744856860] n_past = 11
[1744856860] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381 ]
[1744856860] n_remain: 1022
[1744856860] eval: [ 'If':3381 ]
[1744856860] n_past = 12
[1744856860] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579 ]
[1744856860] n_remain: 1021
[1744856860] eval: [ ' so':579 ]
[1744856860] n_past = 13
[1744856860] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725 ]
[1744856860] n_remain: 1020
[1744856860] eval: [ ',':28725 ]
[1744856860] n_past = 14
[1744856860] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665 ]
[1744856860] n_remain: 1019
[1744856860] eval: [ ' please':4665 ]
[1744856860] n_past = 15
[1744856860] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665, ' share':4098 ]
[1744856860] n_remain: 1018
[1744856860] eval: [ ' share':4098 ]
[1744856860] n_past = 16
[1744856860] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665, ' share':4098, ' what':767 ]
[1744856860] n_remain: 1017
[1744856860] eval: [ ' what':767 ]
[1744856860] n_past = 17
[1744856860] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665, ' share':4098, ' what':767, ' has':659 ]
[1744856860] n_remain: 1016
[1744856860] eval: [ ' has':659 ]
[1744856860] n_past = 18
[1744856860] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665, ' share':4098, ' what':767, ' has':659, ' happened':4243 ]
[1744856860] n_remain: 1015
[1744856860] eval: [ ' happened':4243 ]
[1744856860] n_past = 19
[1744856860] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665, ' share':4098, ' what':767, ' has':659, ' happened':4243, '.':28723 ]
[1744856860] n_remain: 1014
[1744856860] eval: [ '.':28723 ]
[1744856861] n_past = 20
[1744856861] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665, ' share':4098, ' what':767, ' has':659, ' happened':4243, '.':28723, '':13 ]
[1744856861] n_remain: 1013
[1744856861] eval: [ '':13 ]
[1744856861] n_past = 21
[1744856861] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665, ' share':4098, ' what':767, ' has':659, ' happened':4243, '.':28723, '':13, 'Other':15681 ]
[1744856861] n_remain: 1012
[1744856861] eval: [ 'Other':15681 ]
[1744856861] n_past = 22
[1744856861] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665, ' share':4098, ' what':767, ' has':659, ' happened':4243, '.':28723, '':13, 'Other':15681, 'wise':3578 ]
[1744856861] n_remain: 1011
[1744856861] eval: [ 'wise':3578 ]
[1744856861] n_past = 23
[1744856861] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665, ' share':4098, ' what':767, ' has':659, ' happened':4243, '.':28723, '':13, 'Other':15681, 'wise':3578, ',':28725 ]
[1744856861] n_remain: 1010
[1744856861] eval: [ ',':28725 ]
[1744856861] n_past = 24
[1744856861] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665, ' share':4098, ' what':767, ' has':659, ' happened':4243, '.':28723, '':13, 'Other':15681, 'wise':3578, ',':28725, ' let':1346 ]
[1744856861] n_remain: 1009
[1744856861] eval: [ ' let':1346 ]
[1744856861] n_past = 25
[1744856861] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665, ' share':4098, ' what':767, ' has':659, ' happened':4243, '.':28723, '':13, 'Other':15681, 'wise':3578, ',':28725, ' let':1346, ''':28742 ]
[1744856861] n_remain: 1008
[1744856861] eval: [ ''':28742 ]
[1744856861] n_past = 26
[1744856861] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665, ' share':4098, ' what':767, ' has':659, ' happened':4243, '.':28723, '':13, 'Other':15681, 'wise':3578, ',':28725, ' let':1346, ''':28742, 's':28713 ]
[1744856861] n_remain: 1007
[1744856861] eval: [ 's':28713 ]
[1744856861] n_past = 27
[1744856861] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665, ' share':4098, ' what':767, ' has':659, ' happened':4243, '.':28723, '':13, 'Other':15681, 'wise':3578, ',':28725, ' let':1346, ''':28742, 's':28713, ' start':1149 ]
[1744856861] n_remain: 1006
[1744856861] eval: [ ' start':1149 ]
[1744856861] n_past = 28
[1744856861] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665, ' share':4098, ' what':767, ' has':659, ' happened':4243, '.':28723, '':13, 'Other':15681, 'wise':3578, ',':28725, ' let':1346, ''':28742, 's':28713, ' start':1149, ' a':264 ]
[1744856861] n_remain: 1005
[1744856861] eval: [ ' a':264 ]
[1744856861] n_past = 29
[1744856861] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665, ' share':4098, ' what':767, ' has':659, ' happened':4243, '.':28723, '':13, 'Other':15681, 'wise':3578, ',':28725, ' let':1346, ''':28742, 's':28713, ' start':1149, ' a':264, ' new':633 ]
[1744856861] n_remain: 1004
[1744856861] eval: [ ' new':633 ]
[1744856861] n_past = 30
[1744856861] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665, ' share':4098, ' what':767, ' has':659, ' happened':4243, '.':28723, '':13, 'Other':15681, 'wise':3578, ',':28725, ' let':1346, ''':28742, 's':28713, ' start':1149, ' a':264, ' new':633, ' conversation':7114 ]
[1744856861] n_remain: 1003
[1744856861] eval: [ ' conversation':7114 ]
[1744856862] n_past = 31
[1744856862] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665, ' share':4098, ' what':767, ' has':659, ' happened':4243, '.':28723, '':13, 'Other':15681, 'wise':3578, ',':28725, ' let':1346, ''':28742, 's':28713, ' start':1149, ' a':264, ' new':633, ' conversation':7114, '.':28723 ]
[1744856862] n_remain: 1002
[1744856862] eval: [ '.':28723 ]
[1744856862] n_past = 32
[1744856862] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665, ' share':4098, ' what':767, ' has':659, ' happened':4243, '.':28723, '':13, 'Other':15681, 'wise':3578, ',':28725, ' let':1346, ''':28742, 's':28713, ' start':1149, ' a':264, ' new':633, ' conversation':7114, '.':28723, ' ':28705 ]
[1744856862] n_remain: 1001
[1744856862] eval: [ ' ':28705 ]
[1744856862] n_past = 33
[1744856862] last: [ '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':0, '':1, ' Do':2378, ' you':368, ' have':506, ' history':3340, ' from':477, ' our':813, ' previous':3454, ' chat':10706, '?':28804, '':13, 'If':3381, ' so':579, ',':28725, ' please':4665, ' share':4098, ' what':767, ' has':659, ' happened':4243, '.':28723, '':13, 'Other':15681, 'wise':3578, ',':28725, ' let':1346, ''':28742, 's':28713, ' start':1149, ' a':264, ' new':633, ' conversation':7114, '.':28723, ' ':28705, '':2 ]
[1744856862] n_remain: 1000
[1744856862] found EOS token
[1744856862]  [end of text]
[1744856862] 
[1744856862] llama_print_timings:        load time =    1913.05 ms
[1744856862] llama_print_timings:      sample time =       2.70 ms /    24 runs   (    0.11 ms per token,  8888.89 tokens per second)
[1744856862] llama_print_timings: prompt eval time =     362.13 ms /    10 tokens (   36.21 ms per token,    27.61 tokens per second)
[1744856862] llama_print_timings:        eval time =    1980.06 ms /    23 runs   (   86.09 ms per token,    11.62 tokens per second)
[1744856862] llama_print_timings:       total time =    2350.12 ms /    33 tokens
[1744856862] Log end
